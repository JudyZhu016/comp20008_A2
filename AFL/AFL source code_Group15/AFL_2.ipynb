{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from matplotlib import pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "cleaned = pd.read_csv(\"processed_afl_dataset.csv\")\n",
                "cleaned.drop(['Unnamed: 0','GM'], axis=1, inplace=True)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Mutual Information"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Discretization (Binning)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "c = cleaned[['HB','DI','IF','CL','CP','BR']]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "          HB         DI        IF        CL         CP        BR  BR_binned\n0  17.782609  32.739130  5.391304  8.652174  17.782609  1.086957        1.0\n1  16.120000  29.960000  4.400000  7.640000  16.000000  1.120000        1.0\n2  15.782609  30.652174  5.260870  6.391304  11.608696  0.478261        0.0\n3  14.583333  29.333333  4.333333  3.875000   9.041667  1.041667        1.0\n4  13.166667  28.041667  6.500000  4.625000  12.708333  1.000000        1.0\n5  18.750000  32.950000  4.650000  7.500000  15.000000  0.500000        0.0\n6  11.320000  25.760000  2.760000  1.600000   6.360000  0.440000        0.0\n7  15.416667  26.791667  3.791667  5.708333  11.958333  0.458333        0.0\n8  17.800000  32.100000  4.650000  4.400000  11.450000  0.700000        1.0\n9  11.500000  28.454545  5.545455  7.909091  15.181818  1.227273        1.0\n                 HB        DI        IF        CL        CP  BR_binned\nHB         1.000000  0.859024  0.656623  0.783693  0.826426   0.313548\nDI         0.859024  1.000000  0.725310  0.651273  0.768870   0.288387\nIF         0.656623  0.725310  1.000000  0.678611  0.696912   0.299848\nCL         0.783693  0.651273  0.678611  1.000000  0.876429   0.306873\nCP         0.826426  0.768870  0.696912  0.876429  1.000000   0.341063\nBR_binned  0.313548  0.288387  0.299848  0.306873  0.341063   1.000000\n"
                }
            ],
            "source": [
                "from sklearn.preprocessing import KBinsDiscretizer\n",
                "# Create a DataFrame that contains the target variable and the characteristic variables\n",
                "df = pd.DataFrame({'HB': c['HB'], 'DI': c['DI'], 'IF': c['IF'], 'CL': c['CL'], 'CP': c['CP'], 'BR': c['BR']})\n",
                "\n",
                "# Discretize the continuous variable BR into 2 bins\n",
                "n_bins = 2\n",
                "est = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
                "df['BR_binned'] = est.fit_transform(df[['BR']])\n",
                "print(df.head(10))\n",
                "\n",
                "# Claculate the correlation\n",
                "corr_matrix = df[['HB', 'DI', 'IF', 'CL', 'CP', 'BR_binned']].corr()\n",
                "# correlation matrix\n",
                "print(corr_matrix)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# KNN classifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "X_train, X_test, y_train, y_test = train_test_split(df[['HB', 'DI','IF', 'CL', 'CP']], df['BR_binned'], test_size=0.3, random_state=42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "\u003cstyle\u003e#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}\u003c/style\u003e\u003cdiv id=\"sk-container-id-1\" class=\"sk-top-container\"\u003e\u003cdiv class=\"sk-text-repr-fallback\"\u003e\u003cpre\u003eKNeighborsClassifier(n_neighbors=3)\u003c/pre\u003e\u003cb\u003eIn a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. \u003cbr /\u003eOn GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\u003c/b\u003e\u003c/div\u003e\u003cdiv class=\"sk-container\" hidden\u003e\u003cdiv class=\"sk-item\"\u003e\u003cdiv class=\"sk-estimator sk-toggleable\"\u003e\u003cinput class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked\u003e\u003clabel for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\"\u003eKNeighborsClassifier\u003c/label\u003e\u003cdiv class=\"sk-toggleable__content\"\u003e\u003cpre\u003eKNeighborsClassifier(n_neighbors=3)\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e",
                        "text/plain": "KNeighborsClassifier(n_neighbors=3)"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "# Normalize the data\n",
                "scaler = StandardScaler().fit(X_train)\n",
                "X_train = scaler.transform(X_train)\n",
                "X_test = scaler.transform(X_test)\n",
                "\n",
                "# Create knn with k=3\n",
                "knn = KNeighborsClassifier(n_neighbors = 3)\n",
                "knn.fit(X_train, y_train)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Accuracy: 0.9951456310679612\n"
                }
            ],
            "source": [
                "from sklearn.metrics import accuracy_score\n",
                "# Prediction\n",
                "y_pred = knn.predict(X_test)\n",
                "# Evaluation\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "print(\"Accuracy:\", accuracy)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Confusion Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": "\u003cFigure size 640x480 with 2 Axes\u003e"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
                "# cm = confusion matrix (variable name)\n",
                "cm = confusion_matrix(y_test, # test data\n",
                "                      y_pred, # predictions\n",
                "                      labels = knn.classes_) # class labels from the knn model\n",
                "\n",
                "disp = ConfusionMatrixDisplay(confusion_matrix = cm, # pass through the created confusion matrix\n",
                "                              display_labels = knn.classes_) # class labels from the knn model\n",
                "\n",
                "disp.plot()\n",
                "plt.title(\"Confusion Matrix\")\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Bootstrapping (imbalanced data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Accuracy from each bootstrap sample: [0.9658119658119658, 0.9713114754098361, 0.9793388429752066, 0.9682539682539683, 0.9713114754098361, 0.9752066115702479, 0.9647058823529412, 0.9518072289156626, 0.9806201550387597, 0.9806949806949807, 0.968503937007874, 0.9681274900398407, 0.9591836734693877, 0.9884615384615385, 0.963265306122449, 0.9656652360515021, 0.9642857142857143, 0.975609756097561, 0.9607843137254902, 0.9915254237288136, 0.968503937007874, 0.9681274900398407, 0.9644268774703557, 0.9571984435797666, 0.9961538461538462, 0.9693486590038314, 0.972, 0.9838709677419355, 0.967391304347826, 0.983739837398374, 0.9793388429752066, 0.9838056680161943, 0.9839357429718876, 0.9641434262948207, 0.97165991902834, 0.9921568627450981, 0.9688715953307393, 0.9717741935483871, 0.9762845849802372, 0.9839357429718876, 0.9678714859437751, 0.9918032786885246, 0.981203007518797, 0.9839357429718876, 0.9832635983263598, 0.9641434262948207, 0.9766536964980544, 0.9918032786885246, 0.9757085020242915, 0.9790794979079498, 0.970954356846473, 0.9551020408163265, 0.9661654135338346, 0.9918032786885246, 0.9835390946502057, 0.9693486590038314, 0.9683794466403162, 0.9801587301587301, 0.9841897233201581, 0.9676113360323887, 0.9833333333333333, 0.9666666666666667, 0.984313725490196, 0.9651162790697675, 0.9591836734693877, 0.9849056603773585, 0.9745762711864406, 0.9616858237547893, 0.984251968503937, 0.9718875502008032, 0.9757085020242915, 0.9591836734693877, 0.967741935483871, 0.9724409448818898, 0.9796747967479674, 0.9762845849802372, 0.9666666666666667, 0.9724409448818898, 0.9618320610687023, 0.9796747967479674, 0.9536679536679536, 0.96875, 0.9879518072289156, 0.9673469387755103, 0.9789029535864979, 0.9666666666666667, 0.9689922480620154, 0.9838709677419355, 0.987603305785124, 0.9724409448818898, 0.98046875, 0.9769230769230769, 0.9737827715355806, 0.9721115537848606, 0.9802371541501976, 0.9747899159663865, 0.9314516129032258, 0.9606299212598425, 0.9814126394052045, 0.9801587301587301, 0.9770992366412213, 0.9761904761904762, 0.9692307692307692, 0.9920948616600791, 0.9883268482490273, 0.9764705882352941, 0.9631147540983607, 0.9838709677419355, 0.9707112970711297, 0.9669421487603306, 0.9768339768339769, 0.9747899159663865, 0.96484375, 0.9717741935483871, 0.978021978021978, 0.979757085020243, 0.98, 0.968503937007874, 0.9831223628691983, 0.9803149606299213, 0.9838056680161943, 0.967741935483871, 0.9613899613899614, 0.9607843137254902, 0.9722222222222222, 0.9754098360655737, 0.980544747081712, 0.9748953974895398, 0.966804979253112, 0.98046875, 0.9693486590038314, 0.9793388429752066, 0.9758064516129032, 0.9840637450199203, 0.9457364341085271, 0.9682539682539683, 0.9516129032258065, 0.9754098360655737, 0.9844357976653697, 0.9682539682539683, 0.9691119691119691, 0.9678714859437751, 0.9699248120300752, 0.9767441860465116, 0.963265306122449, 0.9565217391304348, 0.9672131147540983, 0.9880952380952381, 0.9631147540983607, 0.9800796812749004, 0.9747899159663865, 0.9693486590038314, 0.9584905660377359, 0.9699570815450643, 0.9693486590038314, 0.9635627530364372, 0.9628099173553719, 0.9653846153846154, 0.9644268774703557, 0.9844357976653697, 0.9703389830508474, 0.9656488549618321, 0.9721115537848606, 0.9722222222222222, 0.9776119402985075, 0.9882352941176471, 0.9676113360323887, 0.9673469387755103, 0.9881422924901185, 0.9762845849802372, 0.9838056680161943, 0.988, 0.9838709677419355, 0.9853479853479854, 0.9689922480620154, 0.9701492537313433, 0.972972972972973, 0.9486166007905138, 0.9765625, 0.9767441860465116, 0.9561752988047809, 0.9755102040816327, 0.9568627450980393, 0.9621848739495799, 0.9695817490494296, 0.9758064516129032, 0.9810606060606061, 0.9753086419753086, 0.9682539682539683, 0.9713114754098361, 0.9673469387755103, 0.951417004048583, 0.9878048780487805, 0.98, 0.979253112033195, 0.9801587301587301, 0.9678714859437751, 0.96, 0.9647058823529412, 0.9840637450199203, 0.9715447154471545, 0.9803921568627451, 0.9541984732824428, 0.9649805447470817, 0.9766536964980544, 0.97265625, 0.9885057471264368, 0.975609756097561, 0.976, 0.9812734082397003, 0.9835390946502057, 0.9696969696969697, 0.9659090909090909, 0.9683794466403162, 0.9715447154471545, 0.9678714859437751, 0.9841269841269841, 0.9721115537848606, 0.9836065573770492, 0.9682539682539683, 0.9757085020242915, 0.9836734693877551, 0.9631147540983607, 0.9877551020408163, 0.9543568464730291, 0.9723320158102767, 0.9683794466403162, 0.9845559845559846, 0.9609375, 0.9793388429752066, 0.9801587301587301, 0.980544747081712, 0.9881889763779528, 0.967741935483871, 0.9765625, 0.9758064516129032, 0.9728682170542635, 0.975103734439834, 0.97265625, 0.9794238683127572, 0.9568627450980393, 0.9793388429752066, 0.9752066115702479, 0.975103734439834, 0.9721115537848606, 0.9635627530364372, 0.9727626459143969, 0.9803149606299213, 0.9803149606299213, 0.9839357429718876, 0.9711934156378601, 0.9710743801652892, 0.9838709677419355, 0.9800796812749004, 0.9878048780487805, 0.9829787234042553, 0.968503937007874, 0.9758064516129032, 0.9676113360323887, 0.968, 0.968, 0.975609756097561, 0.9876543209876543, 0.9591836734693877, 0.9686274509803922, 0.9730769230769231, 0.9759036144578314, 0.9803921568627451, 0.9711934156378601, 0.9601593625498008, 0.9673469387755103, 0.9771863117870723, 0.9689922480620154, 0.9758064516129032, 0.9794238683127572, 0.9718875502008032, 0.9796747967479674, 0.9731800766283525, 0.9764705882352941, 0.9696969696969697, 0.9691119691119691, 0.98046875, 0.968503937007874, 0.9768339768339769, 0.9713114754098361, 0.9835390946502057, 0.9759036144578314, 0.9806201550387597, 0.9721115537848606, 0.9742647058823529, 0.9732824427480916, 0.9734848484848485, 0.9727626459143969, 0.959349593495935, 0.9801587301587301, 0.9682539682539683, 0.9662447257383966, 0.9688715953307393, 0.9794238683127572, 0.9660377358490566, 0.9590163934426229, 0.979757085020243, 0.9808429118773946, 0.9799196787148594, 0.9603174603174603, 0.9571984435797666, 0.9758064516129032, 0.976, 0.9791666666666666, 0.983739837398374, 0.9769230769230769, 0.9875, 0.9747899159663865, 0.9767441860465116, 0.9777777777777777, 0.975609756097561, 0.9676113360323887, 0.98046875, 0.9683794466403162, 0.9722222222222222, 0.9581749049429658, 0.9601593625498008, 0.9616858237547893, 0.9800796812749004, 0.9836734693877551, 0.9846153846153847, 0.9653846153846154, 0.972, 0.9881889763779528, 0.9730769230769231, 0.9683794466403162, 0.9691119691119691, 0.9760956175298805, 0.9774436090225563, 0.984, 0.9626556016597511, 0.9715447154471545, 0.9759036144578314, 0.9642857142857143, 0.9812734082397003, 0.9811320754716981, 0.9795081967213115, 0.9961538461538462, 0.9703389830508474, 0.9732824427480916, 0.9558232931726908, 0.9831932773109243, 0.9798387096774194, 0.9635627530364372, 0.9803149606299213, 0.9625, 0.9703389830508474, 0.9723320158102767, 0.964, 0.9598393574297188, 0.9723320158102767, 0.9803149606299213, 0.9803921568627451, 0.9673469387755103, 0.9717741935483871, 0.9809160305343512, 0.9876543209876543, 0.9807692307692307, 0.9735849056603774, 0.9699570815450643, 0.9841269841269841, 0.9686274509803922, 0.967741935483871, 0.9598393574297188, 0.9767441860465116, 0.9607843137254902, 0.9701492537313433, 0.9669421487603306, 0.9790794979079498, 0.9770114942528736, 0.9799196787148594, 0.9644268774703557, 0.9626556016597511, 0.9757085020242915, 0.9610894941634242, 0.9768339768339769, 0.9606299212598425, 0.9561752988047809, 0.9722222222222222, 0.970954356846473, 0.9711934156378601, 0.9836734693877551, 0.9764705882352941, 0.983402489626556, 0.9686274509803922, 0.9800796812749004, 0.9708333333333333, 0.9798387096774194, 0.976, 0.98828125, 0.9570815450643777, 0.9670781893004116, 0.9655172413793104, 0.972, 0.9588477366255144, 0.9758064516129032, 0.9705882352941176, 0.9818840579710145, 0.9755102040816327, 0.9800796812749004, 0.9796747967479674, 0.9713114754098361, 0.9601593625498008, 0.9727626459143969, 0.976, 0.9615384615384616, 0.991869918699187, 0.9874476987447699, 0.983402489626556, 0.9795081967213115, 0.9757085020242915, 0.9717741935483871, 0.9878542510121457, 0.9798387096774194, 0.9813432835820896, 0.9840637450199203, 0.9596774193548387, 0.987603305785124, 0.9727626459143969, 0.9660377358490566, 0.9838709677419355, 0.9767441860465116, 0.975, 0.9737827715355806, 0.9803149606299213, 0.9844357976653697, 0.9714285714285714, 0.9844961240310077, 0.9764705882352941, 0.9656488549618321, 0.968503937007874, 0.9886792452830189, 0.9841269841269841, 0.9688715953307393, 0.9766536964980544, 0.9689922480620154, 0.9635627530364372, 0.9876543209876543, 0.9764705882352941, 0.9536679536679536, 0.9647058823529412, 0.9739776951672863, 0.9676113360323887, 0.980544747081712, 0.9678714859437751, 0.970954356846473, 0.9840637450199203, 0.9763779527559056, 0.975103734439834, 0.9723320158102767, 0.9781659388646288, 0.9921259842519685, 0.9711934156378601, 0.9704641350210971, 0.952755905511811, 0.9656488549618321, 0.9799196787148594, 0.979757085020243, 0.9838709677419355, 0.9634146341463414, 0.9723320158102767, 0.9561752988047809, 0.9759036144578314, 0.9644268774703557, 0.9723320158102767, 0.963265306122449, 0.975103734439834, 0.9806949806949807, 0.9723320158102767, 0.98, 0.9766536964980544, 0.972, 0.9725490196078431, 0.9645669291338582, 0.97265625, 0.9651162790697675, 0.9795081967213115, 0.9802371541501976, 0.9629629629629629, 0.9723320158102767, 0.9715447154471545, 0.9876543209876543, 0.9625468164794008, 0.9806949806949807, 0.9724409448818898, 0.9730769230769231, 0.976, 0.9543726235741445, 0.9610894941634242, 0.96484375, 0.9681274900398407, 0.9806201550387597, 0.9647058823529412, 0.968, 0.9923664122137404]\nMean accuracy from all bootstrap samples: 0.9733784388715794\n"
                }
            ],
            "source": [
                "# scikit-learn bootstrap\n",
                "from sklearn.utils import resample\n",
                "from sklearn.metrics import recall_score, precision_score, f1_score\n",
                "X = np.array(df[['HB', 'DI','IF', 'CL', 'CP']])\n",
                "y = np.array(df['BR_binned'])\n",
                "n = X.shape[0]\n",
                "dataidx = range(n)\n",
                "k = 500\n",
                "\n",
                "# Storing the metrics for each dataset\n",
                "accuracies = []\n",
                "precisions = []\n",
                "recalls = []\n",
                "\n",
                "# Loop through each dataset, split data based on bootstrapping indices + fit model + evaluate\n",
                "for i in range(k):\n",
                "    # prepare bootstrap sample\n",
                "    boot_index = resample(range(n), replace=True, n_samples=n, random_state=i)\n",
                "    # out of bag observations\n",
                "    oob_index = [x for x in range(n) if x not in boot_index]\n",
                "    # Split datasets\n",
                "    X_train_1 = X[boot_index,:]\n",
                "    X_test_1 = X[oob_index,:]\n",
                "    y_train_1 = y[boot_index]\n",
                "    y_test_1 = y[oob_index]\n",
                "\n",
                "    # Normalize the data\n",
                "    scaler = StandardScaler().fit(X_train_1)\n",
                "    X_train_1 = scaler.transform(X_train_1)\n",
                "    X_test_1 = scaler.transform(X_test_1)\n",
                "\n",
                "    # Train\n",
                "    knn = KNeighborsClassifier(n_neighbors=3)\n",
                "    knn.fit(X_train_1, y_train_1)\n",
                "    \n",
                "    # Predict\n",
                "    y_pred_1 = knn.predict(X_test_1)\n",
                "    \n",
                "    # Evaluate\n",
                "    accuracies.append(accuracy_score(y_test_1, y_pred_1))\n",
                "    precisions.append(precision_score(y_test_1, y_pred_1))\n",
                "    recalls.append(recall_score(y_test_1, y_pred_1))\n",
                "\n",
                "print(\"Accuracy from each bootstrap sample:\", accuracies)\n",
                "#Display average of accuracy scores\n",
                "avg_acc_score = np.mean(accuracies)\n",
                "print(\"Mean accuracy from all bootstrap samples:\", avg_acc_score)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Precision from each bootstrap sample: [0.3333333333333333, 0.25, 0.0, 0.16666666666666666, 0.0, 0.0, 0.2, 0.1111111111111111, 0.5, 1.0, 0.14285714285714285, 0.0, 0.2, 0.75, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.25, 0.2857142857142857, 0.0, 0.75, 0.0, 0.0, 0.25, 0.0, 0.3333333333333333, 0.4, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.6, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.5, 0.6, 1.0, 1.0, 0.4, 1.0, 0.2, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.25, 0.0, 0.0, 0.6666666666666666, 0.5, 0.14285714285714285, 0.5, 0.4, 0.0, 0.3333333333333333, 0.5, 0.0, 0.5, 0.3333333333333333, 0.0, 0.0, 0.5, 0.2222222222222222, 0.25, 0.0, 1.0, 0.1, 0.6666666666666666, 1.0, 0.0, 0.5, 0.2, 0.2857142857142857, 0.6666666666666666, 0.5, 1.0, 0.5, 0.0, 0.0, 0.14285714285714285, 0.75, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.4, 0.25, 0.2, 0.4, 0.2857142857142857, 0.5, 0.5, 1.0, 0.25, 0.0, 0.5, 0.3333333333333333, 0.5, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.5, 1.0, 0.75, 1.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.25, 0.3333333333333333, 0.0, 0.42857142857142855, 0.0, 0.0, 0.25, 0.0, 1.0, 0.25, 0.6666666666666666, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.16666666666666666, 0.25, 0.0, 0.0, 0.5, 0.0, 0.2857142857142857, 0.25, 0.3333333333333333, 0.5, 0.8, 0.0, 1.0, 0.5, 0.2857142857142857, 0.6666666666666666, 1.0, 0.4, 0.0, 0.0, 0.42857142857142855, 0.0, 0.14285714285714285, 0.0, 0.4, 0.25, 0.0, 0.0, 0.0, 0.4, 0.5, 1.0, 1.0, 1.0, 0.25, 0.5, 0.0, 0.5, 0.5, 0.4, 1.0, 0.0, 0.25, 0.0, 1.0, 0.5, 0.5, 0.4, 0.25, 0.6666666666666666, 0.4, 1.0, 0.75, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 0.2, 0.0, 0.14285714285714285, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.5, 0.0, 0.5, 0.6, 0.75, 0.0, 0.5, 0.5, 0.4, 0.0, 0.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.0, 0.25, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.4, 0.0, 0.3333333333333333, 0.25, 0.4, 0.5, 1.0, 0.1111111111111111, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.2, 0.75, 0.25, 0.3333333333333333, 0.25, 1.0, 0.0, 0.5, 0.0, 0.5, 0.3333333333333333, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, 0.5, 0.0, 0.16666666666666666, 0.4, 0.5, 0.3333333333333333, 1.0, 0.5, 0.3333333333333333, 0.3333333333333333, 0.25, 0.0, 0.25, 0.3333333333333333, 0.0, 0.0, 0.25, 0.0, 0.0, 0.4, 0.5, 1.0, 0.0, 0.5, 0.4, 0.6666666666666666, 0.25, 0.25, 0.0, 0.5, 0.0, 0.4, 0.0, 0.0, 0.2, 0.5, 0.4, 0.3333333333333333, 0.16666666666666666, 0.6666666666666666, 0.0, 0.16666666666666666, 0.0, 0.25, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.125, 0.3333333333333333, 1.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.16666666666666666, 0.0, 1.0, 0.16666666666666666, 0.6666666666666666, 0.16666666666666666, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.5, 0.16666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.3333333333333333, 0.25, 0.5, 0.0, 0.16666666666666666, 0.0, 0.5, 0.14285714285714285, 0.3333333333333333, 0.5, 0.0, 1.0, 0.4, 0.0, 0.2222222222222222, 0.2, 0.2, 0.0, 0.0, 0.2857142857142857, 0.3333333333333333, 0.25, 1.0, 0.5, 0.6666666666666666, 0.6666666666666666, 0.25, 0.0, 0.2, 0.0, 0.6666666666666666, 1.0, 0.0, 0.3333333333333333, 0.5, 0.3333333333333333, 0.25, 0.3333333333333333, 0.0, 0.4, 0.0, 0.5, 0.3333333333333333, 0.2, 0.25, 0.3333333333333333, 0.25, 0.3333333333333333, 0.3333333333333333, 0.0, 0.5, 0.0, 0.25, 0.25, 0.3333333333333333, 0.4, 0.5, 0.25, 0.0, 0.3333333333333333, 0.0, 0.25, 1.0, 0.5, 0.5, 0.0, 0.3333333333333333, 0.5, 0.0, 1.0, 0.2857142857142857, 0.16666666666666666, 0.0, 0.0, 0.5, 0.5, 0.5, 0.16666666666666666, 1.0, 0.75, 0.5, 0.14285714285714285, 1.0, 0.4, 0.0, 1.0, 0.3333333333333333, 0.25, 0.0, 1.0, 0.5, 0.0, 0.0, 0.3333333333333333, 0.4, 0.5, 0.0, 0.2857142857142857, 0.3333333333333333, 0.0, 0.5, 0.3333333333333333, 1.0, 0.0, 0.0, 0.5, 0.0, 0.16666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.6666666666666666, 0.4, 0.0, 0.0, 0.5, 0.5, 0.5, 0.6, 0.0, 0.0, 0.3333333333333333, 1.0, 0.14285714285714285, 0.3333333333333333, 0.5, 0.0, 0.6666666666666666, 0.1, 0.0, 0.14285714285714285, 1.0, 0.0, 0.0, 0.5, 1.0]\nMean precision from all bootstrap samples: 0.3392833333333333\n"
                }
            ],
            "source": [
                "print(\"Precision from each bootstrap sample:\", precisions)\n",
                "#Display average of precision scores\n",
                "avg_precision_score = np.mean(precisions)\n",
                "print(\"Mean precision from all bootstrap samples:\", avg_precision_score)\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Recall from each bootstrap sample: [0.14285714285714285, 0.2, 0.0, 0.25, 0.0, 0.0, 0.16666666666666666, 0.2, 0.2, 0.2857142857142857, 0.3333333333333333, 0.0, 0.14285714285714285, 0.6, 0.0, 0.25, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.16666666666666666, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.3333333333333333, 0.5, 0.2, 0.5, 0.0, 0.0, 0.3333333333333333, 0.0, 0.375, 0.14285714285714285, 0.3333333333333333, 0.25, 0.5, 0.0, 0.0, 0.5, 0.3, 0.14285714285714285, 0.3333333333333333, 0.4, 0.375, 0.25, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.16666666666666666, 0.3333333333333333, 0.16666666666666666, 0.0, 0.0, 0.4, 0.1111111111111111, 0.2, 0.25, 0.4, 0.0, 0.3333333333333333, 0.14285714285714285, 0.0, 0.1, 0.14285714285714285, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.2, 0.0, 0.16666666666666666, 0.25, 0.2222222222222222, 0.4, 0.0, 0.4, 0.2, 0.4, 0.4, 0.3333333333333333, 0.2222222222222222, 0.2, 0.0, 0.0, 0.5, 0.42857142857142855, 0.3333333333333333, 0.0, 0.0, 0.2, 0.0, 0.0, 0.2857142857142857, 0.0, 0.3333333333333333, 0.5, 0.14285714285714285, 0.1111111111111111, 0.0, 0.3333333333333333, 0.16666666666666666, 0.3333333333333333, 0.4, 0.3333333333333333, 0.2857142857142857, 0.16666666666666666, 0.2857142857142857, 0.3333333333333333, 0.0, 0.25, 0.25, 0.25, 0.0, 0.14285714285714285, 0.0, 0.25, 0.0, 0.0, 0.2, 0.0, 0.0, 0.375, 0.2857142857142857, 0.375, 0.2, 0.0, 0.14285714285714285, 0.0, 0.2, 0.0, 0.16666666666666666, 0.6, 0.0, 0.42857142857142855, 0.0, 0.0, 0.1111111111111111, 0.0, 0.25, 0.4, 0.3333333333333333, 0.0, 0.0, 0.08333333333333333, 0.16666666666666666, 0.0, 0.2, 0.4, 0.0, 0.0, 0.25, 0.0, 0.3333333333333333, 0.6666666666666666, 0.4, 0.16666666666666666, 0.6666666666666666, 0.0, 0.1111111111111111, 0.3333333333333333, 0.6666666666666666, 0.4, 0.4, 0.6666666666666666, 0.0, 0.0, 0.42857142857142855, 0.0, 0.125, 0.0, 0.4, 0.2857142857142857, 0.0, 0.0, 0.0, 0.2857142857142857, 0.16666666666666666, 0.16666666666666666, 0.14285714285714285, 0.1111111111111111, 0.2, 0.125, 0.0, 0.3333333333333333, 0.2, 0.5, 0.16666666666666666, 0.0, 0.125, 0.0, 0.42857142857142855, 0.14285714285714285, 0.4, 0.4, 0.14285714285714285, 0.2857142857142857, 0.3333333333333333, 0.25, 0.375, 0.2857142857142857, 0.0, 0.4, 0.125, 0.16666666666666666, 0.0, 0.5, 0.14285714285714285, 0.4, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.5, 0.2222222222222222, 0.2222222222222222, 0.0, 0.3333333333333333, 0.0, 0.0, 0.4, 0.0, 0.3333333333333333, 0.3333333333333333, 0.375, 0.0, 0.14285714285714285, 0.16666666666666666, 0.3333333333333333, 0.0, 0.0, 0.2, 0.16666666666666666, 0.16666666666666666, 0.0, 0.2222222222222222, 0.0, 0.6, 0.0, 0.0, 0.2, 0.0, 0.0, 0.3333333333333333, 0.0, 0.2, 0.2857142857142857, 0.0, 0.14285714285714285, 0.16666666666666666, 0.2857142857142857, 0.5, 0.25, 0.3333333333333333, 0.2222222222222222, 0.0, 0.14285714285714285, 0.16666666666666666, 0.0, 0.14285714285714285, 0.3, 0.25, 0.3333333333333333, 0.25, 0.16666666666666666, 0.0, 0.2, 0.0, 0.16666666666666666, 0.14285714285714285, 0.0, 0.16666666666666666, 0.0, 0.2857142857142857, 0.0, 0.0, 0.16666666666666666, 0.16666666666666666, 0.2857142857142857, 0.0, 0.3333333333333333, 0.3333333333333333, 0.2857142857142857, 0.25, 0.16666666666666666, 0.125, 0.14285714285714285, 0.14285714285714285, 0.3333333333333333, 0.0, 0.125, 0.25, 0.0, 0.0, 0.125, 0.0, 0.0, 0.4, 0.8, 0.2, 0.0, 0.6666666666666666, 0.4, 0.2857142857142857, 0.25, 0.25, 0.0, 0.2, 0.0, 0.3333333333333333, 0.0, 0.0, 0.14285714285714285, 0.2, 0.6666666666666666, 0.3333333333333333, 0.2, 0.25, 0.0, 0.3333333333333333, 0.0, 0.16666666666666666, 0.14285714285714285, 0.5, 0.0, 0.0, 0.0, 0.5, 0.3333333333333333, 0.25, 0.2857142857142857, 0.0, 0.5, 0.5, 0.0, 0.6666666666666666, 0.0, 0.16666666666666666, 0.2, 0.3333333333333333, 0.2, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.2, 0.25, 0.0, 0.25, 0.5, 0.16666666666666666, 0.16666666666666666, 0.2, 0.25, 0.0, 0.25, 0.0, 0.16666666666666666, 0.2, 0.14285714285714285, 0.125, 0.0, 0.25, 0.5, 0.0, 0.5, 0.3333333333333333, 0.14285714285714285, 0.0, 0.0, 0.25, 0.16666666666666666, 0.2, 0.3, 0.75, 0.2857142857142857, 0.4, 0.16666666666666666, 0.0, 0.25, 0.0, 0.2857142857142857, 0.4, 0.0, 0.14285714285714285, 0.2222222222222222, 0.16666666666666666, 0.125, 0.2, 0.0, 0.5, 0.0, 0.2, 0.25, 0.25, 0.125, 0.16666666666666666, 0.25, 0.1111111111111111, 1.0, 0.0, 0.25, 0.0, 0.25, 0.2, 0.5, 0.5, 0.2, 0.5, 0.0, 0.5, 0.0, 0.4, 0.2, 0.16666666666666666, 0.16666666666666666, 0.0, 0.25, 0.5, 0.0, 0.3333333333333333, 0.6666666666666666, 0.2, 0.0, 0.0, 0.25, 0.125, 0.16666666666666666, 0.25, 0.1, 0.6, 0.3333333333333333, 0.14285714285714285, 0.1, 0.3333333333333333, 0.0, 0.16666666666666666, 0.14285714285714285, 0.2, 0.0, 0.14285714285714285, 0.16666666666666666, 0.0, 0.0, 1.0, 0.3333333333333333, 0.14285714285714285, 0.0, 0.3333333333333333, 0.25, 0.0, 0.5, 0.125, 0.2222222222222222, 0.0, 0.0, 0.1111111111111111, 0.0, 0.2, 0.0, 0.3333333333333333, 0.4, 0.16666666666666666, 0.2857142857142857, 0.3333333333333333, 0.0, 0.0, 0.2857142857142857, 0.2222222222222222, 0.2, 0.5, 0.0, 0.0, 0.4, 0.25, 0.2, 0.25, 0.2857142857142857, 0.0, 0.2857142857142857, 0.25, 0.0, 0.25, 0.1111111111111111, 0.0, 0.0, 0.125, 0.5]\nMean recall from all bootstrap samples: 0.19681349206349205\n"
                }
            ],
            "source": [
                "print(\"Recall from each bootstrap sample:\", recalls)\n",
                "#Display average of recall scores\n",
                "avg_recall_score = np.mean(recalls)\n",
                "print(\"Mean recall from all bootstrap samples:\", avg_recall_score)"
            ]
        }
    ]
}
